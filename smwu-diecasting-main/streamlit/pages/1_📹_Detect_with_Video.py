import os
import cv2
import streamlit as st
import asyncio
import unicodedata
import time
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor
from translations import init_language, set_language, translations
from utils import (
    get_image_hash,
    hamming_distance,
    resize_and_pad_image,
    crop_image,
    apply_color_jitter,
    add_border,
    invoke_sagemaker_endpoint,
)
import json
import boto3
import numpy as np  

st.set_page_config(page_title="Realtime Detect Video", page_icon="ğŸ“¹")

# ì–¸ì–´ ì´ˆê¸°í™” ë° ì„ íƒ
init_language()
set_language()
current_language = st.session_state["language"]
text = translations[current_language]["video"]


# ë¹„ë™ê¸°ë¡œ SageMaker í˜¸ì¶œ
async def async_invoke_sagemaker(frame_idx, processed_img, loop, executor):
    result = await loop.run_in_executor(
        executor,
        invoke_sagemaker_endpoint,
        "diecasting-model-T7-endpoint",
        processed_img,
    )
    return frame_idx, result


async def realtime_process_video_async(video_path, tolerance=5, frame_interval=2):
    cap = cv2.VideoCapture(video_path)
    prev_hash = None

    frame_index = 0
    part_number = 1
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    current_part_images = []  # í˜„ì¬ ë¶€í’ˆ ì´ë¯¸ì§€ ì €ì¥
    ng_detect = {}
    ok_detect = {}

    # ThreadPoolExecutor ìƒì„±
    loop = asyncio.get_event_loop()
    executor = ThreadPoolExecutor()

    # ë³‘ë ¬ ì‘ì—… ê´€ë¦¬ìš© Semaphore
    semaphore = asyncio.Semaphore(10)  # ìµœëŒ€ ë™ì‹œ Task ìˆ˜ ì œí•œ

    # ì‹¤ì‹œê°„ ì´ë¯¸ì§€ ì¶œë ¥ìš© ì»¨í…Œì´ë„ˆ
    realtime_container = st.empty()

    async def process_frame(frame, frame_idx):
        """ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬"""
        nonlocal prev_hash, current_part_images, part_number

        current_hash = get_image_hash(frame)

        # ì¤‘ë³µ í”„ë ˆì„ ì œê±°
        if prev_hash is None or (
            tolerance < hamming_distance(prev_hash, current_hash) < 40
        ):
            prev_hash = current_hash

            # opencv ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_img = resize_and_pad_image(
                crop_image(apply_color_jitter(frame, brightness=1.0, contrast=1.0), 1.0)
            )
            
            # ë¹„ë™ê¸°ë¡œ SageMaker í˜¸ì¶œ
            frame_idx, result = await async_invoke_sagemaker(
                frame_idx, processed_img, loop, executor
            )

            label = "OK" if result == 1 else "NG"
            label_color = (0, 255, 0) if result == 1 else (0, 0, 255)
            bordered_frame = add_border(frame, label_color)
            

            # ì‘ë‹µ ì €ì¥
            current_part_images.append((frame_idx, bordered_frame, label))
           
            # í”„ë ˆì„ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            current_part_images.sort(key=lambda x: x[0])

            # ì‹¤ì‹œê°„ìœ¼ë¡œ ì´ë¯¸ì§€ ì¶œë ¥
            with realtime_container.container():
                st.markdown(f"### No. {part_number}")
                cols = st.columns(5)
                for idx, (_, img, lbl) in enumerate(current_part_images):
                    cols[idx].image(
                        img,
                        channels="BGR",
                        caption=f"Channel {idx + 1}: {lbl}",
                    )
                

            # ë¶€í’ˆ ìƒíƒœ í™•ì¸ (5ê°œì˜ ì´ë¯¸ì§€ê°€ ëª¨ë‘ ì±„ì›Œì§€ë©´)
            if len(current_part_images) == 5:
                part_status = (
                    "OK"
                    if "NG" not in [lbl for _, _, lbl in current_part_images]
                    else "NG"
                )
               #st.markdown(current_part_images)  #í™•ì¸ìš©
                # ìµœì¢… ì´ë¯¸ì§€ ì €ì¥
                if part_status == "NG":
                    ng_detect[part_number] = [
                        (img, lbl) for _, img, lbl in current_part_images
                    ]
                else:
                    ok_detect[part_number] = [
                        (img, lbl) for _, img, lbl in current_part_images
                    ]

                # ë¶€í’ˆ ìƒíƒœ ì¶œë ¥
                with realtime_container.container():
                    st.markdown(f"### No. {part_number} - {part_status}")
                    cols = st.columns(5)
                    for idx, (_, img, lbl) in enumerate(current_part_images):
                        cols[idx].image(
                            img,
                            channels="BGR",
                            caption=f"Channel {idx + 1}: {lbl}",
                        )

                # ì´ˆê¸°í™”
                current_part_images = []
                realtime_container.empty()
                part_number += 1

    # ì œí•œëœ í”„ë ˆì„ ì²˜ë¦¬ í•¨ìˆ˜ (ë³‘ëª© ë°©ì§€)
    async def limited_process_frame(frame, frame_idx):
        async with semaphore:
            return await process_frame(frame, frame_idx)

    # ì‹¤í–‰ í•¨ìˆ˜
    tasks = []
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break  # ì˜ìƒ ëì— ë„ë‹¬í•œ ê²½ìš°

        # í”„ë ˆì„ ìƒ˜í”Œë§
        if frame_index % frame_interval == 0:
            tasks.append(limited_process_frame(frame, frame_index))

        frame_index += 1

    await asyncio.gather(*tasks)

    cap.release()
    realtime_container.empty()
    return ng_detect, ok_detect


@st.cache_data
def get_cached_images(detect, part_number):
    return detect[part_number]


def show_result_details(detect, status):
    container = st.container()
    with container:
        st.subheader(f"{status} {text["detailed_image"]}")
        selected_part = st.selectbox(
            f"{text["select_img_box"]} : {status}",
            options=list(detect.keys()),
            key=f"select_{status}"
        )

    if selected_part:
        st.subheader(f"No. {selected_part}")
        images = get_cached_images(detect, selected_part)
       
        cols = st.columns(5)
        for idx, (image, label) in enumerate(images):
            cols[idx % 5].image(
                image,
                channels="BGR",
                caption=f"Part {selected_part} - Channel {idx + 1}: {label}",
            )
        

# S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
def get_s3_client():
    return boto3.client(
        "s3",
        aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
        aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
        region_name=os.getenv("AWS_REGION"),
    )

# S3ì— ê²°ê³¼ ì €ì¥
def upload_results_to_s3(bucket_name, key, data):
    s3 = get_s3_client()
    s3.put_object(
        Bucket=bucket_name,
        Key=key,
        Body=json.dumps(data),
        ContentType="application/json",
    )

# S3ì— ì´ë¯¸ì§€ ì—…ë¡œë“œ
def upload_image_to_s3(bucket_name, key, image_data):
    #for i in range(len(image_data)):
    image_data_array = np.array(image_data)
    if len(image_data_array.shape) == 3 and image_data_array.shape[2] == 3:
 #       image_data_array = cv2.cvtColor(image_data_array, cv2.COLOR_BGR2RGB)
        ret, encoded_img = cv2.imencode('.jpg', image_data_array) 
        #st.markdown(encoded_img) #í™•ì¸ìš©
        if not ret:
            raise ValueError("Failed to encode image")
    
    
        with BytesIO() as img_byte_array:
            img_byte_array.write(encoded_img.tobytes())
            img_byte_array.seek(0)
        
       
        #img_encoded = cv`2`.imread(image, 1)
            s3 = get_s3_client()
            s3.put_object(
                Bucket=bucket_name,
                Key=key,
                Body=img_byte_array,
                ContentType="image/jpeg",
            )
    return f"s3://{bucket_name}/{key}"

# S3ì—ì„œ JSON ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
def fetch_results_from_s3(bucket_name, prefix):
    s3 = get_s3_client()
    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)

    results = []
    if "Contents" in response:
        for obj in response["Contents"]:
            key = obj["Key"]
            if key.endswith(".json"):
                json_data = s3.get_object(Bucket=bucket_name, Key=key)["Body"].read()
                results.append(json.loads(json_data))
    return results

# ê²°ê³¼ë¥¼ ë¼ë²¨ë³„ë¡œ ì €ì¥
def save_results_with_images_to_s3(
    bucket_name, video_name, ng_images, ok_images
):
    result_data = {"video_name": video_name, "ng_parts": [], "ok_parts": []}

    for idx in ng_images.keys():
        result_data_in = []
        #st.markdown(ng_images) #í™•ì¸ìš©
        for i in range(len(ng_images[idx])):
            key = f"results/{video_name}/NG_part_{idx}/{i+1}.jpg"
            #st.markdown(idx)   #í™•ì¸ìš©
            #st.markdown(ng_images[idx+1][i][0][0]) #í™•ì¸ìš©
            
            image_url = upload_image_to_s3(bucket_name, key, ng_images[idx][i][0])
            result_data_in.append({"part_number": idx, "image_url": image_url})
            result_data["ng_parts"].append(result_data_in)
        #st.markdown(image_url) #í™•ì¸ìš©
        

    for idx in ok_images.keys():
        result_data_in = []
        #st.markdown(ng_images) #í™•ì¸ìš©
        #st.markdown(idx)
        for i in range(len(ok_images[idx])):
            key = f"results/{video_name}/OK_part_{idx}/{i+1}.jpg"
            #st.markdown(ng_images[idx+1][i][0][0]) #í™•ì¸ìš©
            image_url = upload_image_to_s3(bucket_name, key, ok_images[idx][i][0])
            result_data_in.append({"part_number": idx, "image_url": image_url})
            result_data["ok_parts"].append(result_data_in)
    

    # JSON ë°ì´í„° ì €ì¥
    json_key = f"results/{video_name}/results.json"
    upload_results_to_s3(bucket_name, json_key, result_data)

def print_accuracy(ng_detect, ok_detect, text):
    # ë¶€í’ˆë³„ ìƒíƒœë¥¼ ë¹„êµí•˜ì—¬ ì •í™•ë„ ê³„ì‚°(ë‹¤ì´ì¼€ìŠ¤íŒ….mp4ìš©)
    true_classes = [
        1,
        0,
        1,
        1,
        0,
        1,
        0,
        0,
        1,
        1,
        1,
        0,
        1,
        0,
        0,
        1,
        0,
        1,
        1,
        1,
        1,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        1,
        1,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        1,
        1,
        0,
    ]
    predicted_labels = []  # 0(NG) ë˜ëŠ” 1(OK) ì €ì¥
    predicted_length = len(ng_detect.keys()) + len(ok_detect.keys())
    for i in range(1, predicted_length + 1):  # 1ë¶€í„° ì´ ë¶„ì„ ë¶€í’ˆ ìˆ˜ê¹Œì§€
        if i in ng_detect:
            predicted_labels.append(0)  # NG
        elif i in ok_detect:
            predicted_labels.append(1)  # OK
        else:
            predicted_labels.append(-1)  # ëˆ„ë½ëœ ê²½ìš°

    # ì •í™•ë„ ê³„ì‚°
    correct_predictions = sum(
        1 for p, g in zip(predicted_labels, true_classes) if p == g
    )

    accuracy = (
        (correct_predictions / predicted_length) * 100 if predicted_length > 0 else 0.0
    )

    # ì •í™•ë„ ì¶œë ¥
    st.metric(label=text["accuracy"], value=f"{accuracy:.2f}%")
    # st.subheader(f"{text['accuracy']} : {accuracy:.2f}%")


# ë©”ì¸ í•¨ìˆ˜
def realtime_video_inference():
    st.title(text["title"])

    # S3 ë²„í‚· ì •ë³´
    bucket_name = "cv-7-video"
    results_prefix = "results/"

    uploaded_file = st.file_uploader("Choose a video file", type=["mp4", "mov", "avi"])

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "upload_time" not in st.session_state:
        st.session_state.upload_time = None  # ì—…ë¡œë“œ ì‹œê°„ ì €ì¥
    if "analysis_done" not in st.session_state:
        st.session_state.analysis_done = False  # ë¶„ì„ ìƒíƒœ ì¶”ì 

    if uploaded_file is not None:
        current_upload_time = time.strftime("%Y%m%d_%H%M%S")  # í˜„ì¬ ì—…ë¡œë“œ ì‹œê°„
        # ì´ë¦„ ì¸ì‹ìš© ì •ê·œí™”
        normalized_name = (
            unicodedata.normalize("NFC", uploaded_file.name).lower().strip()
        )
        # ìƒˆ íŒŒì¼ ì—…ë¡œë“œ ì´ë²¤íŠ¸ ì²˜ë¦¬
        if st.session_state.upload_time != current_upload_time:
            # ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.upload_time = current_upload_time
            st.session_state.analysis_done = False

        temp_video_path = f"temp_{uploaded_file.name}"
        with open(temp_video_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        st.success(
            f"{text["upload_success"]} : {uploaded_file.name} ({st.session_state['upload_time']})"
        )
        st.video(temp_video_path, autoplay=True, muted=True)

        if not st.session_state.analysis_done:

            with st.spinner(text["processing"]):
                (
                    ng_detect,
                    ok_detect,
                ) = asyncio.run(
                    realtime_process_video_async(temp_video_path, tolerance=5)
                )
                st.session_state.analysis_done = True

                # ê²°ê³¼ë¥¼ S3ì— ì €ì¥
                result_data = {
                    "video_name": uploaded_file.name,
                    "ng_parts": list(ng_detect.keys()),
                    "ok_parts": list(ok_detect.keys()),
                }
                result_key = f"{results_prefix}{uploaded_file.name}.json"
                ##upload_results_to_s3(bucket_name, result_key, result_data)
                #for i in range(len(ng_detect.keys())):
                #    save_results_with_images_to_s3(
                #    bucket_name, uploaded_file.name, ng_detect[i+1], ok_detect[i+1]
                #)
                #st.success(ng_detect) #í™•ì¸ìš©
                save_results_with_images_to_s3(
                    bucket_name, uploaded_file.name, ng_detect, ok_detect
                )
                
                st.success(f"Results saved to S3: {result_key}")

        # ê²°ê³¼ ì¶œë ¥
        # í•´ë‹¹ ë¹„ë””ì˜¤ì—ë§Œ ì •í™•ë„ ì¶œë ¥
        if "ë‹¤ì´ì¼€ìŠ¤íŒ…" in normalized_name:
            print_accuracy(ng_detect, ok_detect, text)

        st.subheader(text["summary"])
        if len(ng_detect.keys()) > 0:
            if current_language == "en":
                st.error(
                    f"{text['total']} {len(ng_detect.keys())} NG {text['parts']}: {list(ng_detect.keys())}"
                )
            elif current_language == "kr":
                st.error(
                    f"{text['total']} {len(ng_detect.keys())}ê°œì˜ NG {text['parts']}: {list(ng_detect.keys())}"
                )
        if len(ok_detect.keys()) > 0:
            if current_language == "en":
                st.success(
                    f"{text['total']} {len(ok_detect.keys())} OK {text['parts']}: {list(ok_detect.keys())}"
                )
            elif current_language == "kr":
                st.success(
                    f"{text['total']} {len(ok_detect.keys())}ê°œì˜ OK {text['parts']}: {list(ok_detect.keys())}"
                )

        @st.fragment
        def show_ng_section():
            if len(ng_detect) > 0:
                show_result_details(ng_detect, "NG")

        @st.fragment
        def show_ok_section():
            if len(ok_detect) > 0:
                show_result_details(ok_detect, "OK")

        show_ng_section()
        show_ok_section()

        # ì‚­ì œ: ë¶„ì„ì´ ëë‚œ í›„ ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(temp_video_path):
            os.remove(temp_video_path)


if __name__ == "__main__":
    realtime_video_inference()
